---
layout:     post
title:      CapsNet个人理解与总结
subtitle:   CapsNet个人理解与总结
date:       2018-05-22
author:     sunlianglong
header-img: img/post-bg-universe.jpg
catalog: true
tags:
    - Paper
    - CapsNet
    - 胶囊网络
---

### 前言
　　**CapsNet为解决CNN的缺点而生**。其实回过头来再想一下神经网络和CNN这一系列的模型，他们放佛一直在强调特征的识别，通过什么样的方法能够更准确高效的识别图像的特征，就像CapsNet一直在强调他们的Net具有方向、大小等属性的识别和内部联系的生成一样。从这里我感觉出一些顶级Paper的魅力和特点所在，那就是从提出的创新点出发，所有的论点围绕创新点，所有的依据站在巨人的肩膀，解决前人没有解决的问题。那么这样对于读者来说，理解起来就不会很困难。创新点贯穿整篇文章，非常条理清晰，非常有说服力，确实值得我们去研读，去学习。
### 出发点
　　CNN是非常善于捕捉特征是否存在，因为CNN的卷积结构就是为此而设计，但是**在探索特征属性之间的关系（比如相对位置关系、相对大小关系等，特征的方向）上，CNN力不从心**。比如在下面第一幅图中，CNN对于两幅图的识别效果都是人脸，显然这是不正确的。从人类的视觉是别来说，人脸的各个部位都是有相对大小和位置关系的，人的多层视觉系统对于某一固定点的识别过程类似于解析树，从这一点出发，论文应用了前人提出的Capsule。
<center>
<img src=" http://myblog-1253290602.file.myqcloud.com/Paper/paper07.png" width = "300" height = "300"/>
</center>
<center>
<img src=" http://myblog-1253290602.file.myqcloud.com/Paper/paper08.png" width = "300" height = "300"/>
</center>
　　例如，对于下面这幅图的识别过程：
<center>
<img src=" http://myblog-1253290602.file.myqcloud.com/Paper/paper09.jpg" width = "200" height = "200"/>
</center>
　　一个简单的CNN模型可以正确地提取鼻子，眼睛和嘴巴的特征，但是提取出来的特征会错误地激活神经元，得出脸部检测成功的结果。
<center>
<img src=" http://myblog-1253290602.file.myqcloud.com/Paper/paper10.jpg" width = "400" height = "400"/>
</center>
　　如果我们**将每个特征的概率标量表示替换成一个代表很多信息的向量，如，输出的不再是标量x，而是一个包含[可能性，方向，大小]的向量，那么我们就可以检测鼻子，眼睛和耳朵特征之间的方向和大小的一致性**, 得出最后的结论。
<center>
<img src=" http://myblog-1253290602.file.myqcloud.com/Paper/paper11.jpg" width = "400" height = "400"/>
</center>

### Capsule理解
　　Capsule是一组捕获特定特征各种参数的神经元，包括输出特征的可能性，文章通过应用一个非线性保证矢量输出的长度不超过1，这个非线性保持矢量的方向不变。我们将胶囊的输出向量称为活动向量，向量的长度表示检测特征的概率，向量的方向方向代表其参数（属性）。

　　比如，下面的第一行表示神经元检测数字“7”的概率。2-D Capsule通过组合2个神经元形成，该Capsule在检测数字“7”时会输出一个2维向量。
<center>
<img src=" http://myblog-1253290602.file.myqcloud.com/Paper/paper12.jpg" width = "400" height = "400"/>
</center>
　　第二行中，输出的2维向量为v=(0, 0.9)和 v=(0, 0.3)，大小表示为：√(0^2+0.9^2 )=0.9 和 ：√(0^2+0.3^2 )=0.3；第三行中，输出的2维向量为v=(0.2, 0.87)和 v=(0.2, 0.19)，向量的大小仍为0.9和0.3。在这里，我们随意给的0.2代表其向右旋转20度。当然，我们可以再添加两个神经元来捕捉特征的大小和笔画的粗细程度。
<center>
<img src=" http://myblog-1253290602.file.myqcloud.com/Paper/paper13.jpg" width = "200" height = "200"/>
</center>
### Capsule与传统neuron比较
<center>
<img src=" http://myblog-1253290602.file.myqcloud.com/Paper/paper14.png" width = "600" height = "600"/>
</center>
#### 参数更新
　　Capsule里面有两种参数，更新算法如下：

- W_ij: 通过BP算法更新。
- c_ij :通过routing-by-agreement更新，capsule论文中的方法是该原则的其中一种实现方法。

#### 新颖的激活函数
　　使用一个非线性"squashing" 函数来将短矢量缩小到几乎为零，而长矢量缩小到略低于1的长度。
### CapsNet网络结构
　　CapsNet是常规卷积层与capsule版全连接层的结合体，整体架构如下：
<center>
<img src=" http://myblog-1253290602.file.myqcloud.com/Paper/paper15.jpg" width = "600" height = "600"/>
</center>
　　第一层就是普通的CNN层，起像素级局部特征检测作用。原图像是28×28大小第一层采用256个9×9的卷积核，步长为1，得到输出矩阵大小为20×20×256。

　　第二层叫做PrimaryCaps层。PrimaryCaps层的计算过程具有多种理解方式，其中之一为，8个并行的常规卷积层的叠堆。
<center>
<img src=" http://myblog-1253290602.file.myqcloud.com/Paper/paper17.png" width = "400" height = "400"/>
</center>
　　矩阵的shape变换过程如图所示：
<center>
<img src=" http://myblog-1253290602.file.myqcloud.com/Paper/paper16.png" width = "600" height = "600"/>
</center>
　　第二层中每一步的详解如图所示：
<center>
<img src=" http://myblog-1253290602.file.myqcloud.com/Paper/paper18.png" width = "700" height = "700"/>
</center>
　　接下来，将第二层的输出转换成16×10维的向量组，得到第三层。在经过两个全连接和一个Sigmoid层，得到输出。
<center>
<img src=" http://myblog-1253290602.file.myqcloud.com/Paper/paper19.jpg" width = "400" height = "400"/>
</center>